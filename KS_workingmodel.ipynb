{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "import gensim.models.doc2vec as doc2vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data & clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>name</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15 minutes wait to play more?</td>\n",
       "      <td>So I dodged a game, all my mains banned or pic...</td>\n",
       "      <td>2rfxx</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>15 minutes wait to play more? So I dodged a ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>League has to investigate possible fake game b...</td>\n",
       "      <td>Obvious inting in game 5 right before TSM win ...</td>\n",
       "      <td>2rfxx</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>League has to investigate possible fake game b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Xmithie...the Goat, I told you so</td>\n",
       "      <td>Here's what I said about Xmithie years ago...\\...</td>\n",
       "      <td>2rfxx</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Xmithie...the Goat, I told you so Here's what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Whatever happened to that Teacher in Korea who...</td>\n",
       "      <td>Anyone remember this ? It was way back like 20...</td>\n",
       "      <td>2rfxx</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Whatever happened to that Teacher in Korea who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Just got to diamond playing annie only :)</td>\n",
       "      <td>Just wanted to share my excitement with you gu...</td>\n",
       "      <td>2rfxx</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Just got to diamond playing annie only :) Just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Hot Take: TSM vs TL is the Best Finals in LCS ...</td>\n",
       "      <td>As a TSM fan it sucks to lose, but those games...</td>\n",
       "      <td>2rfxx</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Hot Take: TSM vs TL is the Best Finals in LCS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Doublelift never meet Faker before in an offic...</td>\n",
       "      <td>As the title, I just realized somehow Doubleli...</td>\n",
       "      <td>2rfxx</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Doublelift never meet Faker before in an offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Griffin went balls to the walls to make LS loo...</td>\n",
       "      <td>after the whole LS Vs Reddit vs other casters ...</td>\n",
       "      <td>2rfxx</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Griffin went balls to the walls to make LS loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Dodged ranked game due to client bug :)</td>\n",
       "      <td>&amp;#x200B;\\r\\n\\r\\nhttps://i.redd.it/fj8xph83t5s2...</td>\n",
       "      <td>2rfxx</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Dodged ranked game due to client bug :) &amp;#x200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Decided to re-roll the skin shards I had saved...</td>\n",
       "      <td>https://imgur.com/Ezbocp6\\r\\n\\r\\nhttps://imgur...</td>\n",
       "      <td>2rfxx</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>Decided to re-roll the skin shards I had saved...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0                      15 minutes wait to play more?   \n",
       "1           1  League has to investigate possible fake game b...   \n",
       "2           2                  Xmithie...the Goat, I told you so   \n",
       "3           3  Whatever happened to that Teacher in Korea who...   \n",
       "4           4          Just got to diamond playing annie only :)   \n",
       "5           5  Hot Take: TSM vs TL is the Best Finals in LCS ...   \n",
       "6           6  Doublelift never meet Faker before in an offic...   \n",
       "7           7  Griffin went balls to the walls to make LS loo...   \n",
       "8           8            Dodged ranked game due to client bug :)   \n",
       "9           9  Decided to re-roll the skin shards I had saved...   \n",
       "\n",
       "                                                text subreddit_id  \\\n",
       "0  So I dodged a game, all my mains banned or pic...        2rfxx   \n",
       "1  Obvious inting in game 5 right before TSM win ...        2rfxx   \n",
       "2  Here's what I said about Xmithie years ago...\\...        2rfxx   \n",
       "3  Anyone remember this ? It was way back like 20...        2rfxx   \n",
       "4  Just wanted to share my excitement with you gu...        2rfxx   \n",
       "5  As a TSM fan it sucks to lose, but those games...        2rfxx   \n",
       "6  As the title, I just realized somehow Doubleli...        2rfxx   \n",
       "7  after the whole LS Vs Reddit vs other casters ...        2rfxx   \n",
       "8  &#x200B;\\r\\n\\r\\nhttps://i.redd.it/fj8xph83t5s2...        2rfxx   \n",
       "9  https://imgur.com/Ezbocp6\\r\\n\\r\\nhttps://imgur...        2rfxx   \n",
       "\n",
       "              name                                           all_text  \n",
       "0  leagueoflegends  15 minutes wait to play more? So I dodged a ga...  \n",
       "1  leagueoflegends  League has to investigate possible fake game b...  \n",
       "2  leagueoflegends  Xmithie...the Goat, I told you so Here's what ...  \n",
       "3  leagueoflegends  Whatever happened to that Teacher in Korea who...  \n",
       "4  leagueoflegends  Just got to diamond playing annie only :) Just...  \n",
       "5  leagueoflegends  Hot Take: TSM vs TL is the Best Finals in LCS ...  \n",
       "6  leagueoflegends  Doublelift never meet Faker before in an offic...  \n",
       "7  leagueoflegends  Griffin went balls to the walls to make LS loo...  \n",
       "8  leagueoflegends  Dodged ranked game due to client bug :) &#x200...  \n",
       "9  leagueoflegends  Decided to re-roll the skin shards I had saved...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ksmith/Documents/Code/DS1/Unit4_Project/build-post-here-DS/final_test_w_name.csv')\n",
    "df = df.fillna('')\n",
    "df['all_text'] = df['title'] + ' ' + df['text'] # Combining text & titles to one field\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>name</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>[Spoilers] What is that one conspiracy theory ...</td>\n",
       "      <td>Arya is already dead and is actually Jaqen H'g...</td>\n",
       "      <td>2rjz2</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>[Spoilers] What is that one conspiracy theory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>[SPOILERS] The only reunion that I want to see...</td>\n",
       "      <td></td>\n",
       "      <td>2rjz2</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>[SPOILERS] The only reunion that I want to see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>[No Spoilers] How does rising the dead work?</td>\n",
       "      <td>Some stuff I wonder about.\\r\\n\\r\\nHow fresh do...</td>\n",
       "      <td>2rjz2</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>[No Spoilers] How does rising the dead work? S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>[No Spoilers] House Targaryen sigil cross stitch</td>\n",
       "      <td></td>\n",
       "      <td>2rjz2</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>[No Spoilers] House Targaryen sigil cross stitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>[No Spoilers] Need help!!</td>\n",
       "      <td>My exams(very important) are going on and will...</td>\n",
       "      <td>2rjz2</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>[No Spoilers] Need help!! My exams(very import...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "543  [Spoilers] What is that one conspiracy theory ...   \n",
       "544  [SPOILERS] The only reunion that I want to see...   \n",
       "545       [No Spoilers] How does rising the dead work?   \n",
       "546   [No Spoilers] House Targaryen sigil cross stitch   \n",
       "547                          [No Spoilers] Need help!!   \n",
       "\n",
       "                                                  text subreddit_id  \\\n",
       "543  Arya is already dead and is actually Jaqen H'g...        2rjz2   \n",
       "544                                                           2rjz2   \n",
       "545  Some stuff I wonder about.\\r\\n\\r\\nHow fresh do...        2rjz2   \n",
       "546                                                           2rjz2   \n",
       "547  My exams(very important) are going on and will...        2rjz2   \n",
       "\n",
       "              name                                           all_text  \n",
       "543  gameofthrones  [Spoilers] What is that one conspiracy theory ...  \n",
       "544  gameofthrones  [SPOILERS] The only reunion that I want to see...  \n",
       "545  gameofthrones  [No Spoilers] How does rising the dead work? S...  \n",
       "546  gameofthrones  [No Spoilers] House Targaryen sigil cross stitch   \n",
       "547  gameofthrones  [No Spoilers] Need help!! My exams(very import...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20 = ['AskReddit', 'dankmemes', 'memes', 'teenagers', 'aww', 'RocketLeagueExchange', 'Showerthoughts',\n",
    "          'funny', 'me_irl', 'freefolk', 'gameofthrones', 'pics', 'NoStupidQuestions', 'AskOuija',\n",
    "          'unpopularopinion', 'gaming', 'videos', 'politics', 'AmItheAsshole', 'Jokes']\n",
    "\n",
    "data = df[df['name'].isin(top_20)]\n",
    "data = data.drop(data.columns[0], axis=1) # Drop old row index\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all_text'] = df['all_text'].str.replace('http\\S+|www.\\S+', 'link', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.all_text, data.name, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['Why', 'do', 'the', 'Brits', 'drive', 'on', 'the', 'opposite', 'side', 'of', 'the', 'car', 'and', 'the', 'road?'], tags=['Train_0']),\n",
       " TaggedDocument(words=['My', 'dog', 'is', 'miner', '#cz'], tags=['Train_1'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22695/22695 [00:00<00:00, 2854350.33it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 3548280.81it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2709796.44it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2764651.89it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2733294.93it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 3867614.55it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 3034515.90it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2770042.17it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2727421.26it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2710722.44it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2827977.70it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2773431.89it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2791160.25it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2950064.44it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2862590.72it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2760642.94it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2981200.42it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2867765.17it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2852212.18it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2783976.64it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2855035.22it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2826550.15it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2834461.76it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2932885.42it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2904073.75it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2866556.13it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2838688.14it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 3095298.97it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2901860.48it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2956294.58it/s]\n",
      "100%|██████████| 22695/22695 [00:00<00:00, 2915280.21it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "    \n",
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = data.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 23s, sys: 160 ms, total: 2min 23s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5846673520340725\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       gameofthrones       0.86      0.67      0.75       103\n",
      "           teenagers       0.65      0.54      0.59       200\n",
      "           AskReddit       0.82      0.95      0.88      1635\n",
      "                pics       0.26      0.19      0.22        74\n",
      "           dankmemes       0.54      0.40      0.46       189\n",
      "RocketLeagueExchange       0.94      0.96      0.95       337\n",
      "                 aww       0.52      0.54      0.53       304\n",
      "              me_irl       0.42      0.51      0.46       362\n",
      "               funny       0.31      0.50      0.38       652\n",
      "      Showerthoughts       0.39      0.29      0.34       259\n",
      "               memes       0.13      0.03      0.05       294\n",
      "    unpopularopinion       0.72      0.71      0.71       225\n",
      "       AmItheAsshole       0.33      0.21      0.26       126\n",
      "              videos       0.77      0.89      0.83       294\n",
      "            freefolk       0.30      0.23      0.26       570\n",
      "              gaming       0.32      0.16      0.22       222\n",
      "               Jokes       0.45      0.55      0.49        95\n",
      "   NoStupidQuestions       0.54      0.50      0.52       555\n",
      "            AskOuija       0.69      0.52      0.59       179\n",
      "            politics       0.42      0.35      0.38       134\n",
      "\n",
      "         avg / total       0.57      0.58      0.57      6809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=subreddits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bea78ee5a7cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vectors_dbow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation ROC AUC:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "y_pred_proba = logreg.predict_proba(test_vectors_dbow)[:,1]\n",
    "print('Validation ROC AUC:', roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User input test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['me_irl']\n"
     ]
    }
   ],
   "source": [
    "input_title = [\"Python tutorial\"]\n",
    "input_text = [\"I'm looking for a good python tutorial for free online. Any suggestions?\"]\n",
    "all_input = input_title + input_text\n",
    "user_input = model_dbow.infer_vector(all_input, steps=20)\n",
    "user_input = user_input.reshape(1, -1)\n",
    "# # user_vectors_dbow = get_vectors(model_dbow, len(input_test), 300, 'User')\n",
    "print(logreg.predict(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
